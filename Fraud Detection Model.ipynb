{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9063308,"sourceType":"datasetVersion","datasetId":5465782}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/joshuamistal/fraud-detection-model?scriptVersionId=191732560\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n# Models \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\n# # Data Processing Utilities \nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\ntf.autograph.set_verbosity(0)\nnp.set_printoptions(precision=2)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-09T03:57:09.48781Z","iopub.execute_input":"2024-08-09T03:57:09.488229Z","iopub.status.idle":"2024-08-09T03:57:25.519311Z","shell.execute_reply.started":"2024-08-09T03:57:09.488196Z","shell.execute_reply":"2024-08-09T03:57:25.518024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load Dataset\ndf = pd.read_csv(\"/kaggle/input/credit-card-fraud-data/fraud_data.csv\")\n\n#Converting date of birth:'dob' and transaction date and time:'trans_date_trans_time' columns to datetime format\ndf['dob'] = pd.to_datetime(df['dob'], format='%d-%m-%Y')\ndf['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], format='%d-%m-%Y %H:%M')\n\n#Extracting date and time into separate columns\ndf['trans_date'] = df['trans_date_trans_time'].dt.date\ndf['trans_time'] = df['trans_date_trans_time'].dt.time\n\n#Calculating age directly by subtracting year of birth from transaction year\ndf['age'] = df['trans_date'].apply(lambda x: x.year) - df['dob'].dt.year\n\n#Extracting hour of transaction\ndf['transaction_hour'] = df['trans_date_trans_time'].dt.hour\n\n#Dropping irrelevant and problematic is_fraud column\ndf = df.drop(columns=['trans_date_trans_time', 'trans_date', 'dob', 'trans_num','trans_time', 'merchant','state','city'])\ndf['is_fraud'] = df['is_fraud'].astype(str).str.extract(r'(\\d)').fillna(0).astype(int)\n\n# Label encode the categorical variables and set the datatype as integer\ncategorical_columns = [\"category\", \"job\"]\nlabel_encoders = {}\ndf[categorical_columns] = df[categorical_columns].apply(lambda col: label_encoders.setdefault(col.name, LabelEncoder()).fit_transform(col))\ndf['is_fraud'] = df['is_fraud'].astype(int)\n\ndf.info()\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:57:28.138008Z","iopub.execute_input":"2024-08-09T03:57:28.139424Z","iopub.status.idle":"2024-08-09T03:57:28.513527Z","shell.execute_reply.started":"2024-08-09T03:57:28.13938Z","shell.execute_reply":"2024-08-09T03:57:28.512377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset  \nfeatures = [x for x in df.columns if x not in [\"is_fraud\"]] \nX = df[features].values\ny = df[\"is_fraud\"].values\n\n# Splitting the Dataset\nRANDOM_STATE = 1\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.8, random_state = 1, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:57:34.882104Z","iopub.execute_input":"2024-08-09T03:57:34.882493Z","iopub.status.idle":"2024-08-09T03:57:34.896194Z","shell.execute_reply.started":"2024-08-09T03:57:34.882465Z","shell.execute_reply":"2024-08-09T03:57:34.894879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'train samples: {len(X_train)}')\nprint(f'validation samples: {len(X_val)}')\nprint(f'target proportion: {sum(y_train)/len(y_train):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:57:37.896024Z","iopub.execute_input":"2024-08-09T03:57:37.896419Z","iopub.status.idle":"2024-08-09T03:57:37.905148Z","shell.execute_reply.started":"2024-08-09T03:57:37.896392Z","shell.execute_reply":"2024-08-09T03:57:37.903779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Feature Scaling to X \nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:57:41.390293Z","iopub.execute_input":"2024-08-09T03:57:41.391147Z","iopub.status.idle":"2024-08-09T03:57:41.401342Z","shell.execute_reply.started":"2024-08-09T03:57:41.391112Z","shell.execute_reply":"2024-08-09T03:57:41.400064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Decision Tree Model Implementation","metadata":{}},{"cell_type":"code","source":"min_samples_split_list = [2,10, 30, 50, 100, 200, 300] ## If the number is an integer, then it is the actual quantity of samples,\nmax_depth_list = [None, 2, 4, 6, 8, 16, 32] # None means that there is no depth limit.\n\nparam_grid = {\n    'min_samples_split': min_samples_split_list,\n    'max_depth': max_depth_list\n}\n\nRANDOM_STATE = 1","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:57:45.893102Z","iopub.execute_input":"2024-08-09T03:57:45.893522Z","iopub.status.idle":"2024-08-09T03:57:45.900365Z","shell.execute_reply.started":"2024-08-09T03:57:45.89349Z","shell.execute_reply":"2024-08-09T03:57:45.89853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize lists to store accuracies for each combination\naccuracy_list_train = []\naccuracy_list_val = []\n\n# Nested loop to iterate over both min_samples_split and max_depth\nfor min_samples_split in min_samples_split_list:\n    for max_depth in max_depth_list:\n        # Fit the model with both parameters\n        model = DecisionTreeClassifier(min_samples_split=min_samples_split,\n                                       max_depth=max_depth,\n                                       random_state=RANDOM_STATE).fit(X_train, y_train) \n        # Predictions\n        predictions_train = model.predict(X_train)\n        predictions_val = model.predict(X_val)\n        \n        # Calculate accuracy for training and validation datasets\n        accuracy_train = accuracy_score(predictions_train, y_train)\n        accuracy_val = accuracy_score(predictions_val, y_val)\n        \n        # Store the results\n        accuracy_list_train.append((min_samples_split, max_depth, accuracy_train))\n        accuracy_list_val.append((min_samples_split, max_depth, accuracy_val))\n\ndf_train_results = pd.DataFrame(accuracy_list_train, columns=['min_samples_split', 'max_depth', 'accuracy_train'])\ndf_val_results = pd.DataFrame(accuracy_list_val, columns=['min_samples_split', 'max_depth', 'accuracy_val'])\n\n# Extract accuracy for each parameter individually\ntrain_acc_min_samples_split = []\nval_acc_min_samples_split = []\n\ntrain_acc_max_depth = []\nval_acc_max_depth = []\n\n# For min_samples_split (keeping max_depth constant)\nfor min_samples_split in min_samples_split_list:\n    train_acc_min_samples_split.append(df_train_results[df_train_results['min_samples_split'] == min_samples_split]['accuracy_train'].mean())\n    val_acc_min_samples_split.append(df_val_results[df_val_results['min_samples_split'] == min_samples_split]['accuracy_val'].mean())\n\n# For max_depth (keeping min_samples_split constant)\nfor max_depth in max_depth_list:\n    train_acc_max_depth.append(df_train_results[df_train_results['max_depth'] == max_depth]['accuracy_train'].mean())\n    val_acc_max_depth.append(df_val_results[df_val_results['max_depth'] == max_depth]['accuracy_val'].mean())\n\n# Create the subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 4))\n\n# Plot for min_samples_split\nax1.set_title('Train x Validation metrics (min_samples_split)')\nax1.set_xlabel('min_samples_split')\nax1.set_ylabel('accuracy')\nax1.set_xticks(range(len(min_samples_split_list)))\nax1.set_xticklabels(min_samples_split_list)\nax1.plot(train_acc_min_samples_split, marker='o')\nax1.plot(val_acc_min_samples_split, marker='o')\nax1.legend(['Train', 'Validation'])\n\n# Plot for max_depth\nax2.set_title('Train x Validation metrics (max_depth)')\nax2.set_xlabel('max_depth')\nax2.set_ylabel('accuracy')\nax2.set_xticks(range(len(max_depth_list)))\nax2.set_xticklabels(max_depth_list)\nax2.plot(train_acc_max_depth, marker='o')\nax2.plot(val_acc_max_depth, marker='o')\nax2.legend(['Train', 'Validation'])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:57:51.454307Z","iopub.execute_input":"2024-08-09T03:57:51.455727Z","iopub.status.idle":"2024-08-09T03:57:55.107234Z","shell.execute_reply.started":"2024-08-09T03:57:51.455687Z","shell.execute_reply":"2024-08-09T03:57:55.106038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example: We can choose our hyperparameter to be min_samples_split = 30, max_depth = 6\ndecision_tree_model = DecisionTreeClassifier(min_samples_split = 30,\n                                             max_depth = 6,\n                                             random_state = RANDOM_STATE).fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:58:26.213532Z","iopub.execute_input":"2024-08-09T03:58:26.213945Z","iopub.status.idle":"2024-08-09T03:58:26.27489Z","shell.execute_reply.started":"2024-08-09T03:58:26.213915Z","shell.execute_reply":"2024-08-09T03:58:26.273895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Metrics train:\\n\\tAccuracy score: {accuracy_score(decision_tree_model.predict(X_train),y_train):.4f}\")\nprint(f\"Metrics validation:\\n\\tAccuracy score: {accuracy_score(decision_tree_model.predict(X_val),y_val):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:58:28.681379Z","iopub.execute_input":"2024-08-09T03:58:28.681782Z","iopub.status.idle":"2024-08-09T03:58:28.692766Z","shell.execute_reply.started":"2024-08-09T03:58:28.681752Z","shell.execute_reply":"2024-08-09T03:58:28.691639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Random Tree Model Implementation ","metadata":{}},{"cell_type":"code","source":"min_samples_split_list = [2,10, 30, 50, 100, 200, 300] ## If the number is an integer, then it is the actual quantity of samples,\nmax_depth_list = [None, 2, 4, 6, 8, 16, 32] # None means that there is no depth limit.\nn_estimators_list = [10, 50, 100, 200]\n\nparam_grid = {\n    'min_samples_split': min_samples_split_list,\n    'max_depth': max_depth_list, \n    'n_estimators': n_estimators_list\n}","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:58:33.518545Z","iopub.execute_input":"2024-08-09T03:58:33.519006Z","iopub.status.idle":"2024-08-09T03:58:33.527441Z","shell.execute_reply.started":"2024-08-09T03:58:33.518947Z","shell.execute_reply":"2024-08-09T03:58:33.526162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Initializing the model\nrf = RandomForestClassifier(random_state=7)\n\n#Setting up the GridSearchCV\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs = -1, cv= 5 , verbose = 2)\n\n# Fit and train the grid data \ngrid_search.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:58:36.187073Z","iopub.execute_input":"2024-08-09T03:58:36.187482Z","iopub.status.idle":"2024-08-09T04:05:29.620186Z","shell.execute_reply.started":"2024-08-09T03:58:36.187452Z","shell.execute_reply":"2024-08-09T04:05:29.618998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Output of the best parameters and score\nprint(f\"Best Parameters: {grid_search.best_params_}\")\nprint(f\"Best Score: {grid_search.best_score_}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T04:05:29.622318Z","iopub.execute_input":"2024-08-09T04:05:29.622665Z","iopub.status.idle":"2024-08-09T04:05:29.629151Z","shell.execute_reply.started":"2024-08-09T04:05:29.622633Z","shell.execute_reply":"2024-08-09T04:05:29.628004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Metrics train:\\n\\tAccuracy score: {accuracy_score(grid_search.predict(X_train),y_train):.4f}\")\nprint(f\"Metrics validation:\\n\\tAccuracy score: {accuracy_score(grid_search.predict(X_val),y_val):.4f}\")\nconfusion = confusion_matrix(y_val, grid_search.predict(X_val)) #confusion matrix\nprint(confusion)\nreport = classification_report(y_val, grid_search.predict(X_val), output_dict=True)\nprint(f\"Metrics validation (classification report):\")\npd.DataFrame(report).transpose()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T04:05:29.630402Z","iopub.execute_input":"2024-08-09T04:05:29.63072Z","iopub.status.idle":"2024-08-09T04:05:29.80112Z","shell.execute_reply.started":"2024-08-09T04:05:29.630694Z","shell.execute_reply":"2024-08-09T04:05:29.800027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary of the Model's Performance:\n\n**Accuracy (98.30%)**: Indicates that the model correctly classifies 98.30% of the total instances.\n\n**Precision (95.07%)**: Indicates that out of all predicted positive instances, 95.07% are actually positive.\n\n**Recall (91.11%)**: Indicates that out of all actual positive instances, the model correctly identifies 91.11%.\n\n**F1 Score (93.04%)**: This is a harmonic mean of precision and recall, providing a single metric that balances both.\n\n**Specificity (99.33%)**: Indicates that out of all actual negative instances, the model correctly identifies 99.45%\n","metadata":{}},{"cell_type":"markdown","source":"# 3. XGBoost Implementation","metadata":{}},{"cell_type":"code","source":"xgb_model = XGBClassifier(n_estimators = 500, learning_rate = 0.1,verbosity = 2, random_state = RANDOM_STATE)\nxgb_model.fit(X_train,y_train, eval_set = [(X_val,y_val)], early_stopping_rounds = 20)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:49:12.118058Z","iopub.execute_input":"2024-08-09T03:49:12.118416Z","iopub.status.idle":"2024-08-09T03:49:12.949169Z","shell.execute_reply.started":"2024-08-09T03:49:12.11839Z","shell.execute_reply":"2024-08-09T03:49:12.948149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model.best_iteration","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:49:18.973422Z","iopub.execute_input":"2024-08-09T03:49:18.973835Z","iopub.status.idle":"2024-08-09T03:49:18.980844Z","shell.execute_reply.started":"2024-08-09T03:49:18.973802Z","shell.execute_reply":"2024-08-09T03:49:18.979539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Metrics train:\\n\\tAccuracy score: {accuracy_score(xgb_model.predict(X_train),y_train):.4f}\\nMetrics test:\\n\\tAccuracy score: {accuracy_score(xgb_model.predict(X_val),y_val):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T03:49:22.213225Z","iopub.execute_input":"2024-08-09T03:49:22.213797Z","iopub.status.idle":"2024-08-09T03:49:22.265461Z","shell.execute_reply.started":"2024-08-09T03:49:22.213754Z","shell.execute_reply":"2024-08-09T03:49:22.264473Z"},"trusted":true},"execution_count":null,"outputs":[]}]}